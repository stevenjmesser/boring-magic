---
layout: post
title: "Recap of the AI Leaders panel, January 2026"
date: 2026-02-04T21:08:27Z
description: "Thoughts on how artificial intelligence is reshaping day-to-day work on digital teams in government."
image: /assets/images/ai-leaders-panel.png
tags:
 - artificial intelligence
 - speaking
 - talks
 - product management
 - design
---

_Here’s what we said at Ministry of Justice’s [AI Leaders panel](https://events.teams.microsoft.com/event/de1b76ef-757f-4fcd-9ef6-c98d4e480467@c6874728-71e6-41fe-a9e1-2e8c36776ad8), the opening event of their [AI Digital Professions conference](https://www.eventbrite.com/e/ai-digital-professions-conference-tickets-1970192031402?viewDetails=true) in January 2026._

_Thank you to Nikola Goger for the invitation to speak, and thanks too to the other panellists: Tim Paul (Head of User Centred Design at i.AI), Paul Haigh (Chief Technology Officer at Ministry of Justice) and Jan Murdoch (Head of Horizon Scanning at Department for Environment, Food & Rural Affairs)._

### Question: How are you seeing AI change each of your professions or areas? And how do you think this will impact the future of your profession or area?

As the product person, I’ve taken a broader team view rather than focusing solely on product-specific matters. However, I believe the key point Mark highlighted earlier is that writing code isn’t necessarily a bottleneck anymore. This raises questions about how it impacts the rest of your process and overall workflow.

Essentially, it shifts that bottleneck earlier in the value stream. Consequently, you must prioritise establishing solid foundations for product architecture and design. For example, if agents can easily complete tickets quickly, you must ensure these foundations are in place to deliver successful products and services.

There’s a slight advantage to it: delivery could potentially become faster. However, there’s also a risk of delivering the wrong thing. Therefore – if we consider service stages – the alpha stage really should be seen as a way to test various solutions and concepts, really try out different ideas.

You have the ability to explore more divergent thinking, which is a good thing. Therefore, you want to optimise your approach to cycle around the ‘problem understanding, solution exploration’ loop more quickly and more often. This means using design methods that encourage this divergence and generate a variety of ideas, and then methods of testing that give you clear signals on where to converge. 

I think the impact lies in the fact that if we’ve been discussing agile practices for the past decade, we’re transitioning towards a phase where Lean practices and Lean Startup methods will become significantly more integral to our work. Mastering writing hypotheses and measuring outcomes will be crucial. Furthermore embracing experimentation and remaining open to being proven wrong will be incredibly beneficial. 

Now that computers can do the some of the computer tasks, we should look at shifting our focus to human-centric activities. We should look more at using co-design, which offers efficiencies in prototyping and testing. Right now you test a product with five people on one day, make some iterations, then return a few days later to test again. Instead, we could gather groups of people in a room for a few days, allowing them to iterate the product with us and provide valuable feedback. This approach empowers users and generates stronger evidence. (And as many people know, access to users can be a stultifying constraint.)

You know, in the product profession we consistently emphasise falling in love with the problem as an important thing to do. Interestingly, this concept resonates in the private sector too. For example, Y Combinator’s Paul Graham frequently discusses that those startups who secure funding and Y Combinator’s are the ones who are intensely focused on users and obsessed with their problems. This aligns closely with our longstanding focus on prioritising user needs in government digital services. Ultimately, truly understanding the problem and having skilled designers who grasp constraints and engineers who design effective architecture will be crucial in delivering high-quality experiences, especially now more than ever. 
 
We need to become much more strategic and excel at demonstrating outcomes rather than simply pumping out a digital version of a form. 

### Question: Let’s talk limits. Where do you see the limits of AI in public service delivery specifically? So what are the things that should never be automated and what kind of unintended consequences have you seen or you think are there?

Tim’s point about judgement is really important. It’s something we think about working on with Extract, a product that uses AI to extract geospatial data from documents. I did go down a bit of a rabbit hole looking at automated decision-making and how does AI have an impact on professionals?

When you consider professionals like doctors and lawyers, you’re looking at the professionalisation of judgement and decision-making. The way a profession is structured, including its educational pathway, specific behaviours and codes of conduct, this all revolves around explainability and audit-ability. This allows for an in-depth examination and inspection of how decisions were made, meaning you can adjudicate what happened. However, stuffing AI into things introduces a ‘black box’ element, you lose that transparency. And while there are people actively working on explainability and shining a light into the black box, I believe it’s a crucial aspect in considering what not to automate.

Returning to our digital professions, I wanted to discuss product management. I believe a potential danger arises when AI is used for tasks like writing tickets, vision statements or mission briefs. As I joked with Tim a few years ago, product management essentially boils down to prompt engineering! This is partly true because providing sufficient context and direction is crucial for achieving successful outcomes. I still believe this is the core responsibility of the role. 

Therefore, ensuring everyone has a comprehensive understanding of users, their context and the problem space they’re working within, is essential. This, I think, is the true craft of product management. Much of this occurs in tickets, in discussions, and vision statements, among other things. Therefore, I don’t think outsourcing that craft is a good idea. 

Some times I’m okay with it, like writing boring tickets. For example, recently I had to create tickets for implementing an analytics service on some prototype. I went to look at the documentation and realised I didn’t need to do it myself anymore. I could simply point an agent at the documentation and ask them to write a decent ticket. All I had to do was outline the stages I wanted to measure and the metrics I wanted to capture. But the agent was able to write the ticket for me in a very short space of time. 

The danger with using AI in some product jobs is that it’s all about managing context. You need to be careful about what you include in people’s context, and that’s really the craft of product management. So be present, don’t automate that.

### Question: What skill sets do digital professionals need to work effectively with AI in your profession? And what would you advise people to learn?

I mentioned it earlier but I think improving your interpersonal skills – the human stuff – is really beneficial. This includes developing conversation skills, getting better at writing and the ability to bring groups together. Get used to considering and discussing feedback together, having differing points of view. 

I believe we should create more space and time for apprenticeships. Earlier, Paul mentioned hiring _more_ juniors rather than fewer, which is great. It reminds me of Yanagi Soetsu, an arts and crafts historian from the early 20th century. During the period of mechanisation in Korea and Japan, he discussed the importance of preserving craft. He talked about ‘village kilns’ and emphasised the importance of skilled artisans working with apprentices to teach methods and pass on knowledge. I believe this will be incredibly crucial in the coming years, otherwise what’s the social contract we’re signing up to?

At a day-to-day level, I believe simply downloading some open large language models and using them through software like LM Studio will be incredibly beneficial. Start by understanding the differences between various models, observing their responses to prompts and how tweaking them produces different outputs. Learn to control inference, such as extending the context window, and delve into data and statistics. I genuinely think this knowledge will be very handy.

Jeremy Keith once said AI is simply applied statistics, which is both funny and true. Therefore, if you learn the feel of the material, you can get better at using it (or not).